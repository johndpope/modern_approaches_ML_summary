{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange, pi\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/svd_train_v01.csv', delimiter=';')\n",
    "\n",
    "t = np.array(\n",
    "        [ \n",
    "            time.mktime(\n",
    "                datetime.datetime.strptime( strd, \"%d/%m/%Y %H:%M\" ).timetuple() \n",
    "            ) for strd in df[ 't_stamp' ].values \n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "fn = df[ 'T' ].values\n",
    "# normalizing function values (nfn is identical to fn)\n",
    "fn = (fn - min(fn)) / (max(fn)-min(fn))\n",
    "nfn = fn\n",
    "\n",
    "\n",
    "print( \"Average time separation:\", sum((t[ 1: ] - t[:-1]))/(t.shape[0]-1)/(60*60) )\n",
    "\n",
    "\n",
    "\n",
    "# if running in 'adaptive' mode, a sample is used to update the model\n",
    "# only if the absolute prediction error is above a specified threshold\n",
    "adaptive = False\n",
    "errorThreshold = 1.0e-3\n",
    "# if adaptive mode is 'false' then a percentage of the samples is used\n",
    "# for training (first percentage * nbSamples, cf. window 'scanner' below)\n",
    "percentageTraining = 1.0\n",
    "\n",
    "# response values, actual vs predicted (lresp is for the learnt samples/responses)\n",
    "resp = []; xresp = []; xlresp = [];\n",
    "# index of the samples that were used as input for learning\n",
    "lsindx = []\n",
    "\n",
    "\n",
    "\n",
    "# index and size of the window we will use to scan the data; response offset w.r.t. window\n",
    "nbTimeSteps = 10; nbRespValues = 1\n",
    "indx = 0; windowSize = nbTimeSteps; maxModelSamples = 150\n",
    "windowPerturbation = 1; lastTstampOffset = 1; endingGap = lastTstampOffset + nbTimeSteps*windowPerturbation\n",
    "\n",
    "\n",
    "# number of hidden units (rough ann simulation)\n",
    "nbHUnits = 7\n",
    "# initialize a matrix of randow weights (input-hidden layer)\n",
    "rweights = np.random.randn( windowSize, nbHUnits )\n",
    "# output weights (that need to be determined, first random)\n",
    "oweights = np.random.randn( nbHUnits, 1 )\n",
    "\n",
    "\n",
    "\n",
    "# ann svd for the output layer\n",
    "annisvd = None\n",
    "\n",
    "\n",
    "sampleData = None\n",
    "sampleDataResponse = None\n",
    "\n",
    "\n",
    "\n",
    "# counters and basic information (time spent training, nb. of samples, etc.)\n",
    "startt = time.time()\n",
    "\n",
    "trainingTime = 0\n",
    "nbTrainingSamples = 0\n",
    "nbSamples = 0\n",
    "\n",
    "predTstamps = []\n",
    "\n",
    "while indx < t.shape[ 0 ] - nbTimeSteps - endingGap:\n",
    "    \n",
    "    # generate a set of index values (cummulative sum, will be monotonically increasing)\n",
    "    xindx = np.random.randint( 0, windowPerturbation, nbTimeSteps ).reshape( 1, nbTimeSteps )\n",
    "    xindx = np.sort( xindx ); xindx = np.arange( indx, indx+nbTimeSteps ) + np.cumsum( xindx )\n",
    "    # offset the last timestamp as to 'simulate' looking to a distant point\n",
    "    xindx[ -1 ] = xindx[ -1 ] + lastTstampOffset\n",
    "    \n",
    "    # values and timestamps (from the noised function and the fixed-frequency timestamps)\n",
    "    xvalues = nfn[ xindx ].reshape( nbTimeSteps, 1)\n",
    "    #xtstamp = t[ xindx ].reshape( nbTimeSteps, 1 ) # TIMESTAMP\n",
    "    xtstamp = ( t[ xindx ] - t[ indx ] ).reshape( nbTimeSteps, 1 ) # OFFSET\n",
    "    #xtstamp[ 0 ] = t[ xtstamp[0]+indx ] # INSERT TIMESTAMP AT FIRST POSITION\n",
    "\n",
    "    xtstamp = xtstamp[ -1 ]\n",
    "    xtstamp = xtstamp / (3.3*3600.0)\n",
    "    \n",
    "    # construct a sample by stacking together the timestamp and the values\n",
    "    xsample = np.vstack( (xtstamp.reshape((1,1)), xvalues) ).reshape( 1, 1+nbTimeSteps )\n",
    "    # drop the actual 'last' value from the sample (will be used as response)\n",
    "    xsample = xsample[ :, :-1 ]\n",
    "    \n",
    "    # calculate the predicted value for the previously constructed sample\n",
    "    xhlinp = np.dot( xsample, rweights )\n",
    "    xhlinp = 1.0/( 1.0 + np.exp( -0.1*xhlinp ) ) - 0.5\n",
    "        \n",
    "    # predicted response\n",
    "    xpresponse = np.dot( xhlinp.reshape( 1, nbHUnits ), oweights ).reshape( 1, )\n",
    "    error = np.abs( xpresponse-xvalues[-1] )\n",
    "    \n",
    "    xresp = np.append( xresp, xpresponse[ -1 ] )\n",
    "    resp  = np.append( resp, xvalues[ -1 ] )\n",
    "\n",
    "    \n",
    "    if sampleData is None:\n",
    "        sampleData = xsample\n",
    "        sampleDataResponse = xpresponse\n",
    "    else:\n",
    "        sampleData = np.vstack( (sampleData, xsample ) )\n",
    "        sampleDataResponse = np.vstack( (sampleDataResponse, xpresponse) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #predTstamps = np.append( predTstamps, xtstamp[ -1 ] ) # TIMESTAMP\n",
    "    predTstamps = np.append( predTstamps, t[ xindx[-1] ] ) # TIMESTAMP WHEN USING GAPS\n",
    "\n",
    "            \n",
    "    # no svd has been computed up to now, no prediction can be made\n",
    "    if annisvd == None:\n",
    "        \n",
    "        X = xhlinp.reshape( nbHUnits, 1 )\n",
    "        U, s, Vt = np.linalg.svd( X, full_matrices=False )\n",
    "        \n",
    "        annisvd = iSVD( U, s, Vt, updateVt = True  )        \n",
    "        xlresp = [ xvalues[ -1 ] ]\n",
    "        sampleAdded = True\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        if (not adaptive and indx < t.shape[ 0 ] * percentageTraining) or (adaptive and error > errorThreshold):\n",
    "            annisvd.update( xhlinp.reshape( nbHUnits, 1 ) )\n",
    "            xlresp = np.vstack( (xlresp, xvalues[-1]) )                    \n",
    "            \n",
    "            if annisvd.Vt.shape[ 1 ] > maxModelSamples:\n",
    "                try:\n",
    "                    annisvd.downdate( 0 )\n",
    "                    xlresp = xlresp[ 1:, : ]\n",
    "                except:\n",
    "                    print( \"FAILED IN DOWNDATING VIA SVD\")\n",
    "                    \n",
    "    # updating the output weights - note that the update method adds columns\n",
    "    # and NOT rows (as it would be expected for Ax = y); the incremental SVD\n",
    "    # we obtain is thus for A^T - we need however the A^+ (pseudoeinverse of A)\n",
    "    \n",
    "    # if A^T = UsV^T (SVD) and knowing that i. (A^T)+ = Vs^{-1}U^T; and (ii) (A^+)^T = (A^T)^+\n",
    "    # we have that (A^+)^T = Vs^{-1}U^T, following that A^+ = Us^{-1}V^T\n",
    "    \n",
    "    # in order to upate the weights, we need to calculate x = A^+ y            \n",
    "    \n",
    "    if (not adaptive and indx < t.shape[ 0 ] * percentageTraining) or (adaptive and error > errorThreshold) :\n",
    "\n",
    "        tstart = time.time()\n",
    "        nbTrainingSamples = nbTrainingSamples+1\n",
    "\n",
    "        Ux, sx, Vtx = annisvd.svd()\n",
    "\n",
    "        nzindx = sx > 0; sx[ nzindx ] = 1.0/sx[ nzindx ]\n",
    "        oweights = np.dot(\n",
    "            np.dot( Ux, np.dot( np.diag( sx ), Vtx ) ),\n",
    "            xlresp\n",
    "        )\n",
    "        \n",
    "        tend = time.time()\n",
    "        trainingTime = trainingTime + (tend-tstart)\n",
    "        \n",
    "        lsindx = np.append( lsindx, t[ indx ] )\n",
    "    \n",
    "    nbSamples = nbSamples+1\n",
    "    indx = indx+1\n",
    "\n",
    "endt = time.time()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# scaling back the function to actual temperature values\n",
    "fn = ( max(df[ 'T' ].values)-min(df[ 'T' ].values) )*fn + min( df[ 'T' ].values ); nfn = fn\n",
    "# ...similar for actual response and predicted response values\n",
    "resp = (max(fn)-min(fn))*resp +min(fn)\n",
    "xresp = (max(fn)-min(fn))*xresp +min(fn)\n",
    "\n",
    "\n",
    "print( \"Nb of samples:\", nbSamples, \"(\", nbTrainingSamples, \"samples used for training )\" )\n",
    "print( \"Time:\", (endt-startt), \"(\", trainingTime, \"for training )\" )\n",
    "print( \"RMSE:\", ( np.sum((xresp-resp)**2) / resp.shape[ 0 ] )**0.5 )\n",
    "print( \"FRMSE:\", ( np.sum((savgol_filter( xresp, 11, 5, delta=0.015 )-resp)**2) / resp.shape[ 0 ] )**0.5 )\n",
    "\n",
    "\n",
    "def axvlines(xs, **plot_kwargs):\n",
    "    \"\"\"\n",
    "    Draw vertical lines on plot\n",
    "    :param xs: A scalar, list, or 1D array of horizontal offsets\n",
    "    :param plot_kwargs: Keyword arguments to be passed to plot\n",
    "    :return: The plot object corresponding to the lines.\n",
    "    \"\"\"\n",
    "    xs = np.array((xs, ) if np.isscalar(xs) else xs, copy=False)\n",
    "    lims = plt.gca().get_ylim()\n",
    "    x_points = np.repeat(xs[:, None], repeats=3, axis=1).flatten()\n",
    "    y_points = np.repeat(np.array(lims + (np.nan, ))[None, :], repeats=len(xs), axis=0).flatten()\n",
    "    plot = plt.plot(x_points, y_points, scaley = False, **plot_kwargs)\n",
    "    return plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure( 1, figsize = (20, 6), dpi = 50 )\n",
    "ax1 = fig.add_subplot( 111 )\n",
    "\n",
    "ax1.grid( True, color = 'green' )\n",
    "mean = sum( fn )/fn.shape[ 0 ]; delta = 1.0e+2;  ax1.set_ylim( (mean-delta, mean+delta) )\n",
    "\n",
    "#ax1.set_xlim( (1.505*1e+9, 1.507*1e+9) )\n",
    "\n",
    "axvlines( lsindx, linewidth=0.5, color='gray', alpha=0.5 )\n",
    "\n",
    "ax1.plot( predTstamps, np.abs(resp-xresp), 'blue', label = 'Error', alpha = 0.1)\n",
    "ax1.plot( t, nfn, 'blue', label = 'Noised Fn' )\n",
    "ax1.plot( t, fn, 'black', label = 'Support Fn') \n",
    "\n",
    "\n",
    "ax1.plot( predTstamps, xresp, 'green', label = 'Pred', alpha = 0.5 )\n",
    "plt.scatter( predTstamps, xresp, color='blue', alpha = 0.2 )\n",
    "\n",
    "ax1.plot( predTstamps, savgol_filter( xresp, 11, 5, delta=0.015 ), 'red', label = 'FPred', alpha = 0.9 )\n",
    "\n",
    "\n",
    "ax1.legend(loc='upper right', frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
